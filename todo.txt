Todo: In order to force the LLM into a response that we can better understand/work with,
      add the response_format = { "type": "json_object" } to the call (both openai and mistral)
      and add "respond with a json like { cmd=..., description=...}" to the system call...
      As test with this format worked very well.


Todo: add a .wget local command to access web-pages

Todo: The 'Continue?' prompt with gpt 3.5 turbo does not seam to work...

Todo: Add routine to update OpenAI_API_Costs.py

Todo: The file create_new_process.py, creates the example process structure.
      But the code in the prompts needs to be updated by hand.
      A command "Make Default" is required that saves the structure and contents of a proces,
      To be used in future '-create' command.  This will simplify development.

Todo: add syntax for .llm, .clear, .include, and .cmd lines

Todo: need a repository for example processes

Todo: Write macro values to a file, so that they will be reloaded.

Todo: .macros line to insert new values into macros.

Todo: add [05:54:56.354]      Step::╭─ Step: rs:"Prompts/2- Create Relationship Names"
          [05:54:56.355]      Step::│ Model: "gpt-4-1106-preview", Temperature: 0, Max Tokens: 50,000, Response Format: "json_object"
      To the log files.

Todo: Have problem with macro replacement.  Seams to fail though I do not know exactly when.

Todo: Documentation for macros

Todo: Error in --step=99*  if there is no matching file...  Need to add a check for this.

Todo: Need some sort of "Conversation" mode.  Where the user can see the answers, and decide to say "Continue".

Todo: update the log file as the process runs.

